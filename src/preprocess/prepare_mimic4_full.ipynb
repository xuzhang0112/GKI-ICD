{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/baizhiwang/gki_icd\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "os.chdir('/home/baizhiwang/gki_icd/')\n",
    "sys.path[0]='../'\n",
    "!pwd\n",
    "from src.utils import write_pickle, read_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_events = pd.read_csv(\"data/mimic4/discharge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>note_type</th>\n",
       "      <th>note_seq</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032-DS-21</td>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>DS</td>\n",
       "      <td>21</td>\n",
       "      <td>2180-05-07 00:00:00</td>\n",
       "      <td>2180-05-09 15:26:00</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032-DS-22</td>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>DS</td>\n",
       "      <td>22</td>\n",
       "      <td>2180-06-27 00:00:00</td>\n",
       "      <td>2180-07-01 10:15:00</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032-DS-23</td>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>DS</td>\n",
       "      <td>23</td>\n",
       "      <td>2180-07-25 00:00:00</td>\n",
       "      <td>2180-07-25 21:42:00</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032-DS-24</td>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>DS</td>\n",
       "      <td>24</td>\n",
       "      <td>2180-08-07 00:00:00</td>\n",
       "      <td>2180-08-10 05:43:00</td>\n",
       "      <td>\\nName:  ___                     Unit No:   _...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000084-DS-17</td>\n",
       "      <td>10000084</td>\n",
       "      <td>23052089</td>\n",
       "      <td>DS</td>\n",
       "      <td>17</td>\n",
       "      <td>2160-11-25 00:00:00</td>\n",
       "      <td>2160-11-25 15:09:00</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          note_id  subject_id   hadm_id note_type  note_seq  \\\n",
       "0  10000032-DS-21    10000032  22595853        DS        21   \n",
       "1  10000032-DS-22    10000032  22841357        DS        22   \n",
       "2  10000032-DS-23    10000032  29079034        DS        23   \n",
       "3  10000032-DS-24    10000032  25742920        DS        24   \n",
       "4  10000084-DS-17    10000084  23052089        DS        17   \n",
       "\n",
       "             charttime            storetime  \\\n",
       "0  2180-05-07 00:00:00  2180-05-09 15:26:00   \n",
       "1  2180-06-27 00:00:00  2180-07-01 10:15:00   \n",
       "2  2180-07-25 00:00:00  2180-07-25 21:42:00   \n",
       "3  2180-08-07 00:00:00  2180-08-10 05:43:00   \n",
       "4  2160-11-25 00:00:00  2160-11-25 15:09:00   \n",
       "\n",
       "                                                text  \n",
       "0   \\nName:  ___                     Unit No:   _...  \n",
       "1   \\nName:  ___                     Unit No:   _...  \n",
       "2   \\nName:  ___                     Unit No:   _...  \n",
       "3   \\nName:  ___                     Unit No:   _...  \n",
       "4   \\nName:  ___                    Unit No:   __...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadm2subject = {}\n",
    "for i,row in note_events.iterrows():\n",
    "    hadm = row['hadm_id']\n",
    "    subject_id = row['subject_id']\n",
    "    if hadm not in hadm2subject:\n",
    "        hadm2subject[hadm] = subject_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取数据集划分：subject_id, hadm_id, label，并找到原文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "涉及的HADM_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 188533\n",
      "dev 7110\n",
      "test 13709\n"
     ]
    }
   ],
   "source": [
    "hadm_ids = []\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    old_df = pd.read_csv(f\"data/splits/mimic4_icd9/{split}_full_hadm_ids.csv\",header=None)\n",
    "    hadm_ids.extend(old_df[0])\n",
    "    # subject_id.extend(old_df[\"SUBJECT_ID\"])\n",
    "    print(split, len(old_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209352, 331793)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hadm_ids), len(note_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在MIMIC-IV v2.2中NoteEvent中找到每个hadm_id对应的报告文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "331793it [03:03, 1807.25it/s]\n"
     ]
    }
   ],
   "source": [
    "idx2report = {hadm_id: [] for hadm_id in hadm_ids}\n",
    "for i, row in tqdm(note_events.iterrows()):\n",
    "    hadm_id, note_type, note_seq, text = row[\"hadm_id\"], row[\"note_type\"], row[\"note_seq\"], row[\"text\"]\n",
    "    if hadm_id in hadm_ids and note_type == \"DS\":\n",
    "        idx2report[hadm_id].append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查找ICD Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(code, is_diag):\n",
    "    \"\"\"\n",
    "    Put a period in the right place because the MIMIC-3 data files exclude them.\n",
    "    Generally, procedure codes have dots after the first two digits,\n",
    "    while diagnosis codes have dots after the first three digits.\n",
    "    \"\"\"\n",
    "    code = \"\".join(code.split(\".\"))\n",
    "    if is_diag:\n",
    "        if code.startswith(\"E\"):\n",
    "            if len(code) > 4:\n",
    "                code = code[:4] + \".\" + code[4:]\n",
    "        else:\n",
    "            if len(code) > 3:\n",
    "                code = code[:3] + \".\" + code[3:]\n",
    "    else:\n",
    "        code = code[:2] + \".\" + code[2:]\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproc = pd.read_csv(f\"data/mimic4/procedures_icd.csv\", dtype={\"icd_code\": str})\n",
    "dfdiag = pd.read_csv(f\"data/mimic4/diagnoses_icd.csv\", dtype={\"icd_code\": str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICD9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproc9 = dfproc[dfproc[\"icd_version\"] == 9]\n",
    "dfdiag9 = dfdiag[dfdiag[\"icd_version\"] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3243926/2857917965.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  lambda row: str(reformat(str(row[3]), True)), axis=1\n",
      "/tmp/ipykernel_3243926/2857917965.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfdiag9[\"absolute_code\"] = dfdiag9.apply(\n",
      "/tmp/ipykernel_3243926/2857917965.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  lambda row: str(reformat(str(row[4]), False)), axis=1\n",
      "/tmp/ipykernel_3243926/2857917965.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfproc9[\"absolute_code\"] = dfproc9.apply(\n"
     ]
    }
   ],
   "source": [
    "dfdiag9[\"absolute_code\"] = dfdiag9.apply(\n",
    "    lambda row: str(reformat(str(row[3]), True)), axis=1\n",
    ")\n",
    "dfproc9[\"absolute_code\"] = dfproc9.apply(\n",
    "    lambda row: str(reformat(str(row[4]), False)), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcodes9 = pd.concat([dfdiag9, dfproc9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3377950it [02:00, 28137.90it/s]\n"
     ]
    }
   ],
   "source": [
    "hadm2icd = {hadm_id: [] for hadm_id in hadm_ids}\n",
    "for i, row in tqdm(dfcodes9.iterrows()):\n",
    "    hadm_id, icd_code = row[\"hadm_id\"], row[\"absolute_code\"]\n",
    "    if hadm_id in hadm2icd:\n",
    "        hadm2icd[hadm_id].append(icd_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIMIC-IV ICD9 Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    split_df = pd.read_csv(\n",
    "        f\"data/splits/mimic4_icd9/{split}_full_hadm_ids.csv\", header=None\n",
    "    )\n",
    "    split_ids = split_df[0].tolist()\n",
    "    new_df = pd.DataFrame(columns=[\"subject_id\",\"hadm_id\",\"text\",\"label\"])\n",
    "    samples = []\n",
    "    for hadm_id in split_ids:\n",
    "        reports = idx2report[hadm_id]\n",
    "        text = \"\\n\".join(reports)\n",
    "        label = hadm2icd[hadm_id]\n",
    "        subject_id = hadm2subject[hadm_id]\n",
    "        # csv: Series\n",
    "        new_df.loc[i] = pd.Series(\n",
    "            {\"subject_id\": subject_id, \"hadm_id\": hadm_id, \"text\": text,\"label\":label}\n",
    "        )\n",
    "        # pickle: Dict\n",
    "        sample = {}\n",
    "        sample[\"subject_id\"] = subject_id\n",
    "        sample[\"hadm_id\"] = hadm_id\n",
    "        sample[\"text\"] = text\n",
    "        sample[\"label\"] = label\n",
    "        samples.append(sample)\n",
    "    new_df.to_csv(f\"data/mimic4_icd9/{split}.csv\", index=False)\n",
    "    write_pickle(samples, f\"data/mimic4_icd9/{split}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code和相应的Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11331"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic4_icd9_codes = set()\n",
    "for icd_codes in hadm2icd.values():\n",
    "    mimic4_icd9_codes.update(icd_codes)\n",
    "mimic4_icd9_codes = sorted(mimic4_icd9_codes)\n",
    "len(mimic4_icd9_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd9_desc = pd.read_csv(\"data/icd9/reference/ICD9_descriptions.tsv\", sep=\"\\t\")\n",
    "code2desc = dict(zip(icd9_desc[\"code\"], icd9_desc[\"desc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def byLineReader(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            yield line\n",
    "            line = f.readline()\n",
    "    return\n",
    "\n",
    "\n",
    "class UMLS(object):\n",
    "    def __init__(\n",
    "        self, umls_path, source_range=None, lang_range=[\"ENG\"], only_load_dict=False\n",
    "    ):\n",
    "        self.umls_path = umls_path\n",
    "        self.source_range = source_range\n",
    "        self.lang_range = lang_range\n",
    "        self.detect_type()\n",
    "        self.load()\n",
    "        # if not only_load_dict:\n",
    "        #     self.load_rel()\n",
    "        #     self.load_sty()\n",
    "\n",
    "    def detect_type(self):\n",
    "        if os.path.exists(os.path.join(self.umls_path, \"MRCONSO.RRF\")):\n",
    "            self.type = \"RRF\"\n",
    "        else:\n",
    "            self.type = \"txt\"\n",
    "\n",
    "    def load(self):\n",
    "        reader = byLineReader(os.path.join(self.umls_path, \"MRCONSO.\" + self.type))\n",
    "\n",
    "        self.cui2str = {}\n",
    "        self.str2cui = {}\n",
    "        self.icd9_to_cui = {}\n",
    "        self.icd10_to_cui = {}\n",
    "        # self.lui_status = {}\n",
    "        read_count = 0\n",
    "        for line in tqdm(reader, ascii=True):\n",
    "            if self.type == \"txt\":\n",
    "                l = [t.replace('\"', \"\") for t in line.split(\",\")]\n",
    "            else:\n",
    "                l = line.strip().split(\"|\")\n",
    "            cui = l[0]\n",
    "            lang = l[1]\n",
    "            # lui_status = l[2].lower() # p -> preferred\n",
    "            lui = l[3]\n",
    "            source = l[11]\n",
    "            code = l[13]\n",
    "            string = l[14]\n",
    "\n",
    "            if source == \"ICD9CM\":\n",
    "                self.icd9_to_cui[code] = cui\n",
    "\n",
    "            if source == \"ICD10CM\" or source == \"ICD10PCS\":\n",
    "                self.icd10_to_cui[code] = cui\n",
    "\n",
    "            if (self.source_range is None or source in self.source_range) and (\n",
    "                self.lang_range is None or lang in self.lang_range\n",
    "            ):\n",
    "                read_count += 1\n",
    "                self.str2cui[string] = cui\n",
    "                self.str2cui[string.lower()] = cui\n",
    "                clean_string = self.clean(string, clean_bracket=False)\n",
    "                self.str2cui[clean_string] = cui\n",
    "\n",
    "                if not cui in self.cui2str:\n",
    "                    self.cui2str[cui] = set()\n",
    "                self.cui2str[cui].update([string.lower()])\n",
    "                self.cui2str[cui].update([clean_string])\n",
    "\n",
    "            # For debug\n",
    "            # if read_count > 1000:\n",
    "            #     break\n",
    "\n",
    "        self.cui = list(self.cui2str.keys())\n",
    "        shuffle(self.cui)\n",
    "        self.cui_count = len(self.cui)\n",
    "\n",
    "        print(\"cui count:\", self.cui_count)\n",
    "        print(\"str2cui count:\", len(self.str2cui))\n",
    "        print(\"MRCONSO count:\", read_count)\n",
    "\n",
    "    def clean(\n",
    "        self, term, lower=True, clean_NOS=True, clean_bracket=True, clean_dash=True\n",
    "    ):\n",
    "        term = \" \" + term + \" \"\n",
    "        if lower:\n",
    "            term = term.lower()\n",
    "        if clean_NOS:\n",
    "            term = term.replace(\" NOS \", \" \").replace(\" nos \", \" \")\n",
    "        if clean_bracket:\n",
    "            term = re.sub(\"\\\\(.*?\\\\)\", \"\", term)\n",
    "        if clean_dash:\n",
    "            term = term.replace(\"-\", \" \")\n",
    "        term = \" \".join([w for w in term.split() if w])\n",
    "        return term\n",
    "\n",
    "    def icd9_to_str(self, icd):\n",
    "        if icd in self.icd9_to_cui:\n",
    "            cui = self.icd9_to_cui[icd]\n",
    "            str_list = self.cui2str[cui]\n",
    "            str_list = [w for w in str_list if len(w.split()) >= 2 or len(w) >= 7]\n",
    "            return list(str_list)\n",
    "        return []\n",
    "\n",
    "    def icd10_to_str(self, icd):\n",
    "        if icd in self.icd10_to_cui:\n",
    "            cui = self.icd10_to_cui[icd]\n",
    "            str_list = self.cui2str[cui]\n",
    "            str_list = [w for w in str_list if len(w.split()) >= 2 or len(w) >= 7]\n",
    "            return list(str_list)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16709195it [00:56, 295308.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cui count: 3426422\n",
      "str2cui count: 16360443\n",
      "MRCONSO count: 10378059\n"
     ]
    }
   ],
   "source": [
    "umls = UMLS(\"/home/baizhiwang/gki_icd/data/umls/2024AB/META/\", only_load_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11331/11331 [00:07<00:00, 1527.17it/s]\n"
     ]
    }
   ],
   "source": [
    "icd9_desc = pd.DataFrame(columns=[\"code\", \"desc\"])\n",
    "for icd in tqdm(mimic4_icd9_codes):\n",
    "    desc = umls.icd9_to_str(icd)[0]\n",
    "    icd9_desc.loc[len(icd9_desc)] = pd.Series({\"code\": icd, \"desc\": desc})\n",
    "icd9_desc.to_csv(\n",
    "    \"data/mimic4_icd9/codes.csv\", index=False,  sep=\"\\t\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIMIC-IV ICD9_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50_codes = pd.read_csv(\n",
    "    \"data/splits/mimic4_icd9/top50_icd9_code_list.txt\", header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    split_df = pd.read_csv(\n",
    "        f\"data/splits/mimic4_icd9/{split}_50_hadm_ids.csv\", header=None\n",
    "    )\n",
    "    split_ids = split_df[0].tolist()\n",
    "    new_df = pd.DataFrame(columns=[\"subject_id\", \"hadm_id\", \"text\", \"label\"])\n",
    "    samples = []\n",
    "    for hadm_id in split_ids:\n",
    "        reports = idx2report[hadm_id]\n",
    "        text = \"\\n\".join(reports)\n",
    "        label = hadm2icd[hadm_id]\n",
    "        label = [\n",
    "            code for code in label if code in top50_codes[0].tolist()\n",
    "        ]\n",
    "        subject_id = hadm2subject[hadm_id]\n",
    "        # csv: Series\n",
    "        new_df.loc[i] = pd.Series(\n",
    "            {\"subject_id\": subject_id, \"hadm_id\": hadm_id, \"text\": text, \"label\": label}\n",
    "        )\n",
    "        # pickle: Dict\n",
    "        sample = {}\n",
    "        sample[\"subject_id\"] = subject_id\n",
    "        sample[\"hadm_id\"] = hadm_id\n",
    "        sample[\"text\"] = text\n",
    "        sample[\"label\"] = label\n",
    "        samples.append(sample)\n",
    "    new_df.to_csv(f\"data/mimic4_icd9_50/{split}.csv\", index=False)\n",
    "    write_pickle(samples, f\"data/mimic4_icd9_50/{split}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICD-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfproc10 = dfproc[dfproc[\"icd_version\"] == 10]\n",
    "dfdiag10 = dfdiag[dfdiag[\"icd_version\"] == 10]\n",
    "dfcodes10 = pd.concat([dfdiag10, dfproc10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3846225it [02:07, 30079.42it/s]\n"
     ]
    }
   ],
   "source": [
    "hadm2icd10 = {hadm_id: [] for hadm_id in hadm_ids}\n",
    "for i, row in tqdm(dfcodes10.iterrows()):\n",
    "    hadm_id, icd_code = row[\"hadm_id\"], row[\"icd_code\"]\n",
    "    if hadm_id in hadm2icd10:\n",
    "        hadm2icd10[hadm_id].append(icd_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 110442\n",
      "dev 4017\n",
      "test 7851\n"
     ]
    }
   ],
   "source": [
    "hadm_ids = []\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    split_df = pd.read_csv(\n",
    "        f\"data/splits/mimic4_icd10/{split}_full_hadm_ids.csv\", header=None\n",
    "    )\n",
    "    hadm_ids.extend(split_df[0])\n",
    "    print(split, len(split_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "331793it [02:22, 2335.99it/s]\n"
     ]
    }
   ],
   "source": [
    "idx2report = {hadm_id: [] for hadm_id in hadm_ids}\n",
    "hadm2subject = {}\n",
    "for i, row in tqdm(note_events.iterrows()):\n",
    "    subject_id, hadm_id, note_type, note_seq, text = row[\"subject_id\"], row[\"hadm_id\"], row[\"note_type\"], row[\"note_seq\"], row[\"text\"]\n",
    "    if hadm_id in hadm_ids and note_type == \"DS\":\n",
    "        idx2report[hadm_id].append(text)\n",
    "        if hadm_id not in hadm2subject:\n",
    "            hadm2subject[hadm_id] = subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    split_df = pd.read_csv(\n",
    "        f\"data/splits/mimic4_icd10/{split}_full_hadm_ids.csv\", header=None\n",
    "    )\n",
    "    split_ids = split_df[0].tolist()\n",
    "    new_df = pd.DataFrame(columns=[\"subject_id\", \"hadm_id\", \"text\", \"label\"])\n",
    "    samples = []\n",
    "    for hadm_id in split_ids:\n",
    "        if hadm_id == 23024122:\n",
    "            continue\n",
    "        reports = idx2report[hadm_id]\n",
    "        text = \"\\n\".join(reports)\n",
    "        label = hadm2icd10[hadm_id]\n",
    "        subject_id = hadm2subject[hadm_id]\n",
    "        # csv: Series\n",
    "        new_df.loc[i] = pd.Series(\n",
    "            {\"subject_id\": subject_id, \"hadm_id\": hadm_id, \"text\": text, \"label\": label}\n",
    "        )\n",
    "        # pickle: Dict\n",
    "        sample = {}\n",
    "        sample[\"subject_id\"] = subject_id\n",
    "        sample[\"hadm_id\"] = hadm_id\n",
    "        sample[\"text\"] = text\n",
    "        sample[\"label\"] = label\n",
    "        samples.append(sample)\n",
    "    new_df.to_csv(f\"data/mimic4_icd10/{split}.csv\", index=False)\n",
    "    write_pickle(samples, f\"data/mimic4_icd10/{split}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIMIC-IV ICD10 Top50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50_codes = pd.read_csv(\n",
    "    \"data/splits/mimic4_icd10/top50_icd10_code_list.txt\", header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    split_df = pd.read_csv(\n",
    "        f\"data/splits/mimic4_icd10/{split}_50_hadm_ids.csv\", header=None\n",
    "    )\n",
    "    split_ids = split_df[0].tolist()\n",
    "    new_df = pd.DataFrame(columns=[\"subject_id\", \"hadm_id\", \"text\", \"label\"])\n",
    "    samples = []\n",
    "    for hadm_id in split_ids:\n",
    "        if hadm_id == 23024122:\n",
    "            continue\n",
    "        reports = idx2report[hadm_id]\n",
    "        text = \"\\n\".join(reports)\n",
    "        label = hadm2icd10[hadm_id]\n",
    "        label = [code for code in label if code in top50_codes[0].tolist()]\n",
    "        subject_id = hadm2subject[hadm_id]\n",
    "        # csv: Series\n",
    "        new_df.loc[i] = pd.Series(\n",
    "            {\"subject_id\": subject_id, \"hadm_id\": hadm_id, \"text\": text, \"label\": label}\n",
    "        )\n",
    "        # pickle: Dict\n",
    "        sample = {}\n",
    "        sample[\"subject_id\"] = subject_id\n",
    "        sample[\"hadm_id\"] = hadm_id\n",
    "        sample[\"text\"] = text\n",
    "        sample[\"label\"] = label\n",
    "        samples.append(sample)\n",
    "    new_df.to_csv(f\"data/mimic4_icd10_50/{split}.csv\", index=False)\n",
    "    write_pickle(samples, f\"data/mimic4_icd10_50/{split}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Final Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188533"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = read_pickle(\"data/mimic4_icd9/train.pkl\")\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for dic in train_data:\n",
    "    if len(dic[\"label\"]) == 0:\n",
    "        print(dic[\"label\"])\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
